{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab9 / simple autoencoder : using Mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此lab中，我們使用lab5的的Mnist手寫數字影像資料集，將影像先encode（編碼）成一小於原始input維度的feature，再將這個feature透過decode（解碼）回原始影像維度。\n",
    "\n",
    "模型的loss為輸出影像（autoencoder後的影像）和原始影像的誤差，最小化這個誤差，使輸出影像接近原始影像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from scipy import spatial\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and plot data image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1,n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_train[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ x_train的維度: (60000, 28, 28) 60000筆28x28的影像\n",
    "+ y_train的維度: (60000,) 60000筆x_train影像的正確數字\n",
    "+ x_test的維度: (10000, 28, 28) 10000筆28x28的影像\n",
    "+ y_test的維度: (10000,) 10000筆x_test影像的正確數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看訓練資料跟測試資料的維度。\n",
    "print(\"x_train的維度: \" + str(x_train.shape)) # (60000, 28, 28)\n",
    "print(\"y_train的維度: \" + str(y_train.shape))# (60000,)\n",
    "print(\"x_test的維度: \" + str(x_test.shape)) # (10000, 28, 28)\n",
    "print(\"y_test的維度: \" + str(y_test.shape)) # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此資料集中有x（圖片）與y (圖片對應正確數字)，我們只會用到圖片部分：x_train和x_test，來訓練此autoencoder模型。\n",
    "\n",
    "x_train為training set，x_test做為訓練模型的validation set。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "正規化資料數值範圍至 [0, 1] 間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將維度28x28的影像reshape成長度784的array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1) # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape) #(60000, 784)\n",
    "print(x_test.shape) #(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build autoencoder architecture\n",
    "\n",
    "![autoencoder_schema](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n",
    "(source: https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "Autoencoder架構中可分為 encoder（編碼器）和 decoder（解碼器）兩部分，它們分別進行壓縮與解壓縮。\n",
    "\n",
    "encoder將input壓縮成小於原始維度的feature，達到「降維」的作用，再透過decoder重建此壓縮後的feature，得到output。模型的loss為輸出影像和原始影像的誤差，最小化這個誤差，使輸出影像接近原始影像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input為reshape過的array, shape為(784,)\n",
    "inputs = tf.keras.Input(shape=(784,))\n",
    "\n",
    "#################### encoder ####################\n",
    "\n",
    "### 請設計3層的encoder hidden layers，記得使用activation\n",
    "### [hint] encoder是做「壓縮」，每層output neuron數通常會越來越小\n",
    "### START CODE HERE ### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ### \n",
    "\n",
    "## size of bottleneck: 2\n",
    "encoder_output = tf.keras.layers.Dense(2)(#output of last encoder layer#)\n",
    " \n",
    "##################### decoder ####################\n",
    "### 請設計3層的decoder hidden layers，記得使用activation\n",
    "### [hint] 1. decoder的input為encoder最後的output\n",
    "###        2. decoder是做「解壓」，每層output neuron數通常會越來越大。此三層的nueron數可以和encoder順序相反\n",
    "### START CODE HERE ### \n",
    "\n",
    "\n",
    "    \n",
    "### END CODE HERE ### \n",
    "\n",
    "## size of decoder output : 與模型的input相同\n",
    "decoder_output = tf.keras.layers.Dense(784, activation='sigmoid')(#output of last decoder layer#)\n",
    " \n",
    "encoder = tf.keras.Model(inputs=inputs,outputs=encoder_output)\n",
    "autoencoder = tf.keras.Model(inputs=inputs, outputs=decoder_output)\n",
    " \n",
    "# compile autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### autoencoder model training: \n",
    "### 請訓練autoendoer模型，以x_train自己為x與y，以x_test作為validation的x與y，\n",
    "### 並設定參數如epochs,batch_size\n",
    "\n",
    "### START CODE HERE ### \n",
    "\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot encoder result\n",
    "\n",
    "在訓練完autoencoder後，我們只先使用前面的encoder部分predict x_test圖片，將其2維結果畫在一平面上，並標上每個點對應的y_test(顏色)。\n",
    "\n",
    "可以看到encoder的結果就像壓縮一樣將其特徵壓縮成2維（降維），且成功將不同的數字區分開來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用encoder層model predict , input 為x_test\n",
    "test_encode = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode.shape #維度(10000,2) 每筆資料被壓縮成2維特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(test_encode[:, 0], test_encode[:, 1], c=y_test, s=3)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image retreival : using encoder feature\n",
    "\n",
    "了解到encoded結果的2維特徵能成功的分群出數字後，我們也能使用這層的特徵來搜尋相似的影像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用test的encoded output其中一筆作為query資料，搜尋在train encoded output中與他最像的前5筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "\n",
    "# 從test_encode中取一筆query資料\n",
    "query_index = 15\n",
    "query = test_encode[query_index]\n",
    "\n",
    "# 計算query與全部train_encode資料的相似度\n",
    "for j in train_encode:\n",
    "    # cosine similarity = 1 - cosine distance\n",
    "    cosine = 1 - spatial.distance.cosine(query,j)\n",
    "    similarity.append(cosine)\n",
    "similarity = pd.Series(similarity)\n",
    "\n",
    "#依相似度做降冪排序\n",
    "sorting = similarity.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#畫出query圖片\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.imshow(x_test[query_index].reshape(28, 28))\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#畫出與query最像的5筆圖片\n",
    "top_n = 5\n",
    "for num,i in enumerate(sorting.index[0:top_n]):\n",
    "    ax = plt.subplot(2, top_n, num + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder 解壓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = autoencoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot original input image and autoencoder result\n",
    "\n",
    "畫出原始input圖片與autoencoder的output圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(result[i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 請嘗試調整模型、訓練參數，最小化loss，並查看image retreival結果與原始、解壓圖片的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
